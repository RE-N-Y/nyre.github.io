---
layout: single
title: "ML in Production"
classes: wide
---

In last two articles, we focused on methodologies on deploying ML code to production.
However, building a ML service in production introduces unique challenges on top of software engineering.
In traditional software development, programmers only need to manage **code** which determines the behavior of their software. However, ML introduces two additional layer of complexity: **data** and **model**. Here, I will share chanlleges and solutions for serving a ML model in production.

## Manual to Automated

From the dawn of time, programmers have been transforming manual processes into automated ones.
In early days of data analytics, data came in formats of excel/csv files. It was sufficient for a single data scientist to clean/validate/engineer data and share their findings. However, in order to serve these findings to a larger audience, it's necessary to break-down data scientist's tasks into automated pipeline.

- **Data Tasks**

1. Data Collection: Public Dataset, Internal data souce, External API
2. Data pre-processing: normalization, one-hot-encoding, binning, log-transforms
3. Data cleaning: data imputation, dropping outliers, dropping correlated features

- **Model Tasks**

1. Model Training
2. Hyperparameter Tuning
3. Model Serving

- **Production Tasks**

1. Model performance monitoring
2. Continous training
3. Data monitoring

Often in research environment, it's sufficient to end here. However, in production, the underlying data distributions are constantly evoling as new data is streaming in. Hence, in most cases, it's absolutely necessary to monitor the performance of production model and retrain the model as performance slows degrades. With these obstacles in mind, we need to manage **production tasks** as well as **data and model tasks**. The question comes down to how we can **automate** these manual processes.

## MLOps
