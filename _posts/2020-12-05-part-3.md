---
layout: single
title: "ML to Production - Part 3"
collection: ML to Production
classes: wide
---

In our last article, we successfully deployed **iris flower classification service** to production. However, like life itself, our ML service is subject to change, which introduces the necessity of **testing**. The goal of this article is to introduce the reader to the subject of automated testing.

## Test, test, test

For a reader with software developer background, automated tests and test-driven-development (TDD) is a familiar concept. However, for a data scientist and ML researcher, it may not be entirely clear why such practice is necessary. Before directly introducting tools and methods for adding automated tests, it's necessary to establish clear understanding of merits it brings.

Consider the following _simple_ code:

```python
def mean(num_list):
    total = 0
    for num in num_list:
        total += num
    return total / len(num_list)
```

Can you think of potential issues that this farily standard code can run into? What about these inputs?

1. `mean(None)`
2. `mean(["hello", "world"])`
3. `mean([])`
4. `mean([float("inf")])`
5. `mean([1,[1,2],1])`

Now, `mean` doesn't seem so safe, does it? Even for a 5-line program, it's clear that if this code is to be used in a production environment with thousands of users, you would want to at least **test** that this function works as expected for variety of inputs.

Taking a step further, imagine having to test _hundreds_ of classes and functions manually, not only it's unfeasible and tedicious, it would be impossible to keep track of individual expectations and test cases. Moreover, as new code is introduced as features, bugs, and refractoring, it's crucial to test that the code can **deliver its expectations under constant changes**. Of course, writing test cost is an investment, but it's a cost worth investing. But, as a developer, the true merit of having automated test suite is that:

> Developers can have **confidence** in the code they ship, and can **sleep at night** without worrying about their code breaking in production.

With these ideas in mind, let's add automated testing to our **iris classification service**.

## Testing in python

At its core, **iris classification service** needs to ensure that given the dimension of an iris flower, it needs to return an integer 0, 1, 2, or 3 which corresponds to the flower's classification. First, let's recall our codebase.

```python
# iris.py

from flask import Flask, jsonify, request
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

# Train model on initialization
X, y = load_iris(return_X_y=True)
clf = DecisionTreeClassifier()
clf = clf.fit(X, y)

app = Flask(__name__)

# Receive inputs via POST request
@app.route("/", methods=["POST"])
def predict():
    sl, sw, pl, pw = request.json["sl"], request.json["sw"], request.json["pl"], request.json["pw"]
    data = [[sl, sw, pl, pw]]
    prediction = clf.predict(data).tolist()

    # Return prediction as JSON
    return jsonify(prediction=prediction)
```

Here, the API code and prediction code is encapsulated in single method, so let's decouple prediction code for testing.

```python
# iris.py

from flask import Flask, jsonify, request
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

def train():
    X, y = load_iris(return_X_y=True)
    clf = DecisionTreeClassifier()
    clf.fit(X, y)

    return clf

def predict(model, data):
    return model.predict(data).tolist()

# Train model on initialization
clf = train()
app = Flask(__name__)

# Receive inputs via POST request
@app.route("/", methods=["POST"])
def root():
    sl, sw, pl, pw = request.json["sl"], request.json["sw"], request.json["pl"], request.json["pw"]
    data = [[sl, sw, pl, pw]]

    prediction = predict(clf, data)

    # Return prediction as JSON
    return jsonify(prediction=prediction)
```

Using [pytest](https://docs.pytest.org/en/stable/), a popular testing framework in python let's ensure that our service meets our expectations. In `/api` folder, let's create a file named `test_iris.py` to write pytest code.

```python
# test_iris.py
import pytest
from iris import train, predict

def test_predict():
    clf = train()
    actual = predict(clf, [[2.0, 1.0, 3.0 ,1.0]])

    # verify predict returns a list
    assert isinstance(actual, list)
    for n in actual:
        # classifications should be one of 0,1,2,3
        assert n == 0. or n == 1. or n == 2. or n == 3.
```

Finally, open up a local terminal at `/api`, and run `pip install pytest` to install pytest. Once it's ready, run `pytest` to check if our code passes the test.

![test]({{ site.url }}{{ site.baseurl }}/assets/images/test.png){: .align-center}
`Automated test suites`
{: .text-center}

Perfect, now, by simply running `pytest` command we can perform automated tests. By adding `pytest` to the Dockerfile, we can automate testing as a part of build process.

```bash
FROM python:3.7-slim
WORKDIR /app
ENV PORT 8080

# Install python dependencies
RUN pip install flask gunicorn
RUN pip install scikit-learn xgboost

# Install test dependancies
RUN pip install pytest

# Copy code
COPY . .

# Run test
pytest

CMD exec gunicorn --bind :$PORT iris:app
```

## Automation with Github Actions

So far, we have progressed from manually testing iris classification service from terminal to setting up automated tests with pytest. However, the process of building and deploying the service to GCP is still left manual. We can easily automate this process with [Github Actions](https://github.com/features/actions). Github Actions is a service provided by Github where developers can trigger workflows (running builds, tests, deployments) based on triggers such as commits, pull requests, and webhooks.

To write a workflow, let's create a `.github/workflows/auto.yml` file under `/api`.

```bash
/api
├── .github/workflows/auto.yml
├── iris.py
├── test_iris.py
├── Dockerfile
```

Our deployment process consists of two steps:

1. Building Docker image in GCP: `gcloud builds submit --tag gcr.io/<PROJECT-ID>/api`
2. Deploying to Cloud Run: `gcloud run deploy --image gcr.io/<PROJECT-ID>/api`

The goal of the workflow will be to run these `gcloud` commands inside Github's machine. In order to allow Github's machines to access our project securely, a **service account key** is required to authorize workflows. A GCP service account can be easily created by navigating to **GCP project console-> IAM & Admin-> Service account**.

![sa]({{ site.url }}{{ site.baseurl }}/assets/images/sa.png){: .align-center .half-scale}
`Service account`
{: .text-center}

Ensure that the service account has following rights:

- Cloud Build Editor
- Service Account User
- Cloud Run Admin
- Viewer

Upon creation, GCP will provide **service account JSON**, which contains private key to authorize Github Actions to deploy the service on the developer's behalf. Developers can securely add service account JSON by navigating to **Settings > Secrets** in Github repository.

In [Github Secrets](https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets), add secrets **GCP_KEY** with contents of **service account JSON** and **PROJECT_ID** with **GCP Project ID**. With service account set-up, let's author the worklfow.

```yml
name: Build & Publish pipeline

# trigger workflow on push to master branch
on:
  push:
    branches:
      - master

{% raw %}
# encryted secret to GCP
env:
  PROJECT_ID: ${{ secrets.PROJECT_ID }}
  GCS_KEY: ${{ secrets.GCS_KEY }}
{% endraw %}

jobs:
  setup-build:
    name: Setup, Build, Deploy
    runs-on: ubuntu-latest

    steps:
      # checkout code from github repository
      - name: Checkout
        uses: actions/checkout@v2

      # set-up gcloud command
      - uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
        with:
          service_account_key: ${{ secrets.GCS_KEY }}
          project_id: ${{ secrets.PROJECT_ID }}

      # run docker build
      - name: Build
        run: |-
          gcloud builds submit \
            --quiet \
            --tag "gcr.io/$PROJECT_ID/api" \

      # deploy to cloud run
      - name: Deploy
        run: |-
          gcloud run deploy \
            --quiet \
            --allow-unauthenticated \
            --region us-east1 \
            --image "gcr.io/$PROJECT_ID/api" \
            --platform "managed" \
```

Now, on every push to master branch, Github will trigger auto.yml and automatically build, test, and deploy **iris classification service** to Cloud Run! Developers can check the status of the workflows in Github and also read the live-logs from Github servers.

![live-logs]({{ site.url }}{{ site.baseurl }}/assets/images/live-logs.png){: .align-center}
`Github Actions`
{: .text-center}

This practice of integrating build, test, and deployment into development process is called Continous Integration / Continous Deployment (CI/CD).

## Ending Remarks and Future directions

In this series of articles, we began by taking an ML code for iris classification and built an infrasture around and development workflow to deploy its functionality into a production environment. Let's review the tools and services at hand.

- **Flask**: API wrapper for ML code
- **Docker**: Ensures runtime consistency between development and production machines
- **Cloud Build & Cloud Run**: Docker build / deployment solution for GCP
- **pytest**: Testing framework
- **Github Actions**: Build, test, deploy workflow automation

Of course, depending on specific use-cases, the choice of tools are intechangable. One could easily replace Cloud Build & Cloud Run with AWS CodeBuild & AWS Fargate, replace Flask with Django, replace pytest with unittest, replace Github Actions with CircleCI. Most major Cloud providers (AWS/Azure/GCP) offer managed solutions for deploying ML models, however, understanding the challegnes, solution, tools, and underlying mechanics is essential.

I would like to make a remark that the I have intentionally chosen **minimal ML code** to focus on process of releasing existing ML code to production. ML researchers and Data scientists are used to working with clean, stable data. However, in the real world, data is streaming in from multiple ingestion sources and the performance of ML model is constantly degrading as underlying data distribution changes. A successful ML system requires a robust data engineering pipeline.

Lastly, designing an ML system involves many underwater rocks that one can encounter, but thankfully, many great designers and engineers have fought through these issues. Here, I will introduce in-depth guides and resources which will further introduce the reader to world of MLOps.

1. [Rules of ML](https://developers.google.com/machine-learning/guides/rules-of-ml),
2. [Introduction to MLOps](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning),
3. [Unoffical Google Data Science Blog](https://www.unofficialgoogledatascience.com/)
4. [ML Design Patterns](https://github.com/mercari/ml-system-design-pattern)
5. [ml-ops.org](https://ml-ops.org/)

On that note, I hope this series of articles will help facilitate ML researchers and Data scientist to deploy their research into production environment. At the end of the day, technology exists for the betterment of society.
